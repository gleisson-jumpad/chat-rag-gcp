import streamlit as st
import os
import uuid
from rag_utils import process_uploaded_file, is_supported_file, SUPPORTED_EXTENSIONS, get_existing_tables
import time
from llama_index.llms.openai import OpenAI as LlamaOpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.vector_stores.postgres import PGVectorStore
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.core.indices.query.query_transform.base import StepDecomposeQueryTransform
from llama_index.core.query_engine import RouterQueryEngine

st.set_page_config(page_title="Chat RAG", layout="wide")

st.title("üí¨ Chat RAG ‚Äì Jumpad")

# Initialize session state for storing uploaded files info
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []

# Sidebar menu
menu = st.sidebar.radio("Navega√ß√£o", [
    "üè† In√≠cio",
    "üîå Teste de Conex√£o com PostgreSQL",
    "üì• Upload e Vetoriza√ß√£o de Arquivos",
    "üîç Consulta com RAG",
    "üß™ Diagn√≥stico Avan√ßado",
])

# P√°ginas do menu
if menu == "üè† In√≠cio":
    st.subheader("Bem-vindo ao sistema de RAG da Jumpad!")
    st.markdown("Use o menu lateral para navegar entre testes e funcionalidades do sistema.")
    
    # Add explanation about LlamaIndex and OpenAI API integration
    st.markdown("## Sobre a Integra√ß√£o LlamaIndex com OpenAI API")
    st.markdown("""
    Este sistema utiliza LlamaIndex com integra√ß√£o direta √† API da OpenAI para:
    
    1. **Processamento de Documentos**: Convertemos seus documentos em chunks e criamos embeddings usando o modelo `text-embedding-ada-002` da OpenAI.
    
    2. **Armazenamento de Vetores**: Os embeddings s√£o armazenados em um banco PostgreSQL com suporte a vetores.
    
    3. **Consulta Sem√¢ntica**: Suas perguntas s√£o convertidas em vetores e comparadas aos documentos atrav√©s de busca por similaridade.
    
    4. **Gera√ß√£o Aumentada**: O LLM da OpenAI (GPT-4o ou GPT-3.5 Turbo) recebe os fragmentos relevantes de documento para gerar respostas precisas.
    """)

elif menu == "üîå Teste de Conex√£o com PostgreSQL":
    st.subheader("üîå Teste de Conex√£o com o Banco")
    try:
        from db_config import get_pg_connection
        conn = get_pg_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT version();")
        version = cursor.fetchone()[0]
        st.success("‚úÖ Conex√£o estabelecida com sucesso!")
        st.code(version)
        cursor.close()
        conn.close()
    except Exception as e:
        st.error("‚ùå Erro ao conectar ao banco de dados:")
        st.code(str(e))

elif menu == "üì• Upload e Vetoriza√ß√£o de Arquivos":
    st.subheader("üì• Upload e Vetoriza√ß√£o de Arquivos")
    
    # Check if we need to import existing documents
    if len(st.session_state.uploaded_files) == 0:
        st.info("üìã Verificando documentos existentes no banco de dados...")
        try:
            # Get document tables using our utility function
            vector_tables = get_existing_tables()
            
            if vector_tables:
                # Connect to database to get document info
                from db_config import get_pg_connection
                conn = get_pg_connection()
                cursor = conn.cursor()
                
                doc_count = 0
                unique_files = set()
                
                for table_name in vector_tables:
                    try:
                        # Query to extract file names from metadata_
                        cursor.execute(f"""
                            SELECT DISTINCT metadata_->>'file_name' as file_name 
                            FROM {table_name}
                            WHERE metadata_->>'file_name' IS NOT NULL
                        """)
                        
                        # Get unique filenames
                        distinct_files = cursor.fetchall()
                        
                        if distinct_files:
                            for file_info in distinct_files:
                                file_name = file_info[0] if file_info[0] else f"Documento {doc_count+1}"
                                
                                # Only add if we haven't seen this file before
                                if file_name not in unique_files:
                                    unique_files.add(file_name)
                                    
                                    # Add document info to session state
                                    st.session_state.uploaded_files.append({
                                        'name': file_name,
                                        'size': 0,
                                        'table': table_name,
                                        'file_id': f"{table_name}_{doc_count}"
                                    })
                                    doc_count += 1
                    except Exception as e:
                        st.warning(f"Erro ao extrair informa√ß√µes da tabela {table_name}: {str(e)}")
                
                cursor.close()
                conn.close()
                
                st.success(f"‚úÖ Encontrados {len(st.session_state.uploaded_files)} documentos processados!")
            else:
                st.warning("Nenhuma tabela de vetores encontrada no banco de dados.")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel verificar documentos existentes: {str(e)}")
    
    # Display supported file types
    st.info(f"Formatos suportados: {', '.join(SUPPORTED_EXTENSIONS)}")
    
    # File uploader
    uploaded_file = st.file_uploader("Escolha um arquivo para processar", type=[ext[1:] for ext in SUPPORTED_EXTENSIONS])
    
    if uploaded_file is not None:
        # Show file details
        st.write(f"**Arquivo:** {uploaded_file.name} ({uploaded_file.size} bytes)")
        
        # Process button
        if st.button("Processar e Vetorizar"):
            with st.spinner("Processando documento e gerando vetores..."):
                try:
                    # Use the utility function from rag_utils.py
                    index = process_uploaded_file(uploaded_file, st.session_state.session_id)
                    
                    # Store file info in session state
                    if uploaded_file.name not in [f['name'] for f in st.session_state.uploaded_files]:
                        st.session_state.uploaded_files.append({
                            'name': uploaded_file.name,
                            'size': uploaded_file.size,
                            'table': f"vectors_{st.session_state.session_id}"
                        })
                    
                    st.success(f"‚úÖ Documento '{uploaded_file.name}' processado e vetorizado com sucesso!")
                    st.info(f"Vetores armazenados na tabela: vectors_{st.session_state.session_id}")
                except Exception as e:
                    st.error(f"‚ùå Erro ao processar o documento: {str(e)}")
    
    # Display uploaded files
    if st.session_state.uploaded_files:
        st.subheader("Arquivos Processados")
        for idx, file_info in enumerate(st.session_state.uploaded_files):
            st.write(f"{idx+1}. **{file_info['name']}** - Tabela: {file_info['table']}")

elif menu == "üîç Consulta com RAG":
    st.subheader("üí¨ ChatRAG Multi-Tabela")
    
    # Initialize chat history if it doesn't exist
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        
    # Initialize multi-table RAG tool if not already done
    if 'multi_rag_tool' not in st.session_state:
        from multi_table_rag import MultiTableRAGTool
        with st.spinner("Inicializando ferramenta RAG multi-tabela..."):
            try:
                # Validate OpenAI API key first
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if not openai_api_key:
                    st.error("‚ùå OPENAI_API_KEY n√£o est√° definida no ambiente.")
                    st.info("Configure a chave API da OpenAI nas vari√°veis de ambiente ou no arquivo .env")
                    st.stop()
                
                # Initialize the RAG tool
                st.session_state.multi_rag_tool = MultiTableRAGTool()
                
                # Run database checks
                db_status = st.session_state.multi_rag_tool.check_postgres_connection()
                if not db_status.get("postgres_connection", False):
                    st.error(f"‚ùå Falha na conex√£o com PostgreSQL: {db_status.get('error', 'Erro desconhecido')}")
                    st.warning("Verifique as configura√ß√µes do banco de dados e a conex√£o com a internet.")
                    st.stop()
                
                if not db_status.get("pgvector_installed", False):
                    st.warning("‚ö†Ô∏è Extens√£o pgvector n√£o est√° instalada no PostgreSQL.")
                    st.info("As opera√ß√µes vetoriais n√£o funcionar√£o sem essa extens√£o.")
                
                # Check for vector tables
                if db_status.get("vector_table_count", 0) == 0:
                    st.warning("‚ö†Ô∏è Nenhuma tabela de vetores encontrada no banco de dados.")
                    st.info("Fa√ßa upload de documentos na se√ß√£o 'Upload e Vetoriza√ß√£o de Arquivos' primeiro.")
                
            except Exception as init_error:
                st.error(f"‚ùå Erro ao inicializar MultiTableRAGTool: {init_error}")
                st.warning("Verifique as configura√ß√µes do banco de dados e a chave da API OpenAI.")
                st.stop() # Stop execution if initialization fails
    
    # Display model selection in the sidebar
    with st.sidebar:
        st.subheader("Configura√ß√µes do Chat")
        
        # --- Add Refresh Button ---
        if st.button("üîÑ Recarregar Ferramenta RAG", help="For√ßa a reinicializa√ß√£o da ferramenta RAG para descobrir novas tabelas/documentos."):
            if 'multi_rag_tool' in st.session_state:
                del st.session_state['multi_rag_tool'] # Remove old instance
            st.success("Ferramenta RAG reinicializada. Recarregando a p√°gina...")
            time.sleep(1) # Brief pause
            st.rerun()
        st.markdown("---")
        # ------------------------
        
        # Model selection with cleaner layout
        st.markdown("**Modelo de IA:**")
        model_options = {
            "GPT-3.5 Turbo": "gpt-3.5-turbo",
            "GPT-4o": "gpt-4o",
            "GPT-4o-mini": "gpt-4o-mini"
        }
        selected_model = st.radio("", list(model_options.keys()), index=1)
        model_id = model_options[selected_model]
        
        st.markdown("---")
        
        # Get table information for display
        tables_info = []
        for table_config in st.session_state.multi_rag_tool.table_configs:
            tables_info.append({
                "name": table_config["name"],
                "docs": table_config.get("doc_count", "?"),
                "chunks": table_config.get("chunk_count", "?"),
                "files": table_config.get("files", [])
            })
        
        # Display tables information in sidebar
        if tables_info:
            st.markdown("**Tabelas de Conhecimento:**")
            for table in tables_info:
                with st.expander(f"{table['name']} ({table['docs']} docs)"):
                    st.write(f"Chunks: {table['chunks']}")
                    if table['files']:
                        st.markdown("**Arquivos:**")
                        for file in table['files']:
                            st.markdown(f"- {file}")
        else:
            st.info("Nenhuma tabela de dados encontrada")
            st.markdown("Fa√ßa o upload de documentos na se√ß√£o **Upload e Vetoriza√ß√£o de Arquivos**")
    
    # Display chat messages from history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Accept user input
    if prompt := st.chat_input("Digite sua pergunta..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Display user message in chat
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generate and display response
        with st.chat_message("assistant"):
            with st.spinner("Procurando nos documentos..."):
                try:
                    # Create a robust system prompt for better RAG
                    system_prompt = """
                    Voc√™ √© um assistente de IA especializado em responder perguntas com base em documentos espec√≠ficos. 
                    Analise cuidadosamente as informa√ß√µes fornecidas pela ferramenta RAG e utilize apenas essas informa√ß√µes ao responder.
                    
                    Diretrizes importantes:
                    - Responda SOMENTE com base nos documentos fornecidos
                    - Se a informa√ß√£o n√£o estiver clara nos documentos, admita que n√£o sabe
                    - N√£o invente ou infira informa√ß√µes al√©m do que est√° explicitamente nos documentos
                    - Seja direto e conciso em suas respostas
                    """
                    
                    # Process the message with RAG integration
                    from postgres_rag_tool import process_message_with_selective_rag
                    
                    response = process_message_with_selective_rag(
                        prompt, 
                        st.session_state.multi_rag_tool, 
                        model=model_id
                    )
                    
                    # Check for empty responses
                    if not response or response.strip() == "":
                        response = "N√£o consegui encontrar informa√ß√µes relevantes nos documentos para responder essa pergunta."
                    
                    # Display the response
                    st.markdown(response)
                    
                except Exception as e:
                    error_msg = f"‚ùå Erro ao processar a consulta: {str(e)}"
                    st.error(error_msg)
                    response = error_msg
            
            # Add response to chat history
            st.session_state.messages.append({"role": "assistant", "content": response})

elif menu == "üß™ Diagn√≥stico Avan√ßado":
    st.subheader("üß™ Diagn√≥stico do Sistema RAG")
    
    # Check OpenAI API key
    api_key_tab, db_tab, vector_tab = st.tabs(["API OpenAI", "Banco de Dados", "Tabelas Vetoriais"])
    
    with api_key_tab:
        st.subheader("Verifica√ß√£o da API da OpenAI")
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key:
            # Check if key starts with "sk-"
            if openai_api_key.startswith("sk-"):
                # Mask the key
                masked_key = f"sk-...{openai_api_key[-4:]}"
                st.success(f"‚úÖ Chave da API OpenAI configurada: {masked_key}")
                
                # Try a simple API call
                try:
                    import openai
                    response = openai.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": "Test connection"}],
                        max_tokens=5
                    )
                    st.success("‚úÖ Conex√£o com a API OpenAI testada com sucesso!")
                except Exception as e:
                    st.error(f"‚ùå Erro ao conectar √† API OpenAI: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è A chave da API OpenAI n√£o parece estar em formato v√°lido (deve come√ßar com 'sk-')")
        else:
            st.error("‚ùå A chave da API OpenAI n√£o est√° configurada!")
            st.info("Configure a vari√°vel de ambiente OPENAI_API_KEY ou adicione ao arquivo .env")
    
    with db_tab:
        st.subheader("Diagn√≥stico do Banco de Dados")
        
        with st.spinner("Verificando conex√£o com PostgreSQL..."):
            try:
                from db_config import get_pg_connection
                conn = get_pg_connection()
                cursor = conn.cursor()
                
                # Check PostgreSQL version
                cursor.execute("SELECT version();")
                pg_version = cursor.fetchone()[0]
                st.success(f"‚úÖ Conex√£o PostgreSQL: {pg_version}")
                
                # Check pgvector extension
                cursor.execute("SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';")
                pgvector_info = cursor.fetchone()
                
                if pgvector_info:
                    st.success(f"‚úÖ Extens√£o pgvector instalada (vers√£o {pgvector_info[1]})")
                    
                    # Check if the extension is working correctly
                    try:
                        cursor.execute("SELECT '[1,2,3]'::vector <-> '[4,5,6]'::vector;")
                        distance = cursor.fetchone()[0]
                        st.success(f"‚úÖ Opera√ß√µes vetoriais funcionando corretamente (dist√¢ncia teste: {distance:.4f})")
                    except Exception as ve:
                        st.error(f"‚ùå Erro ao testar opera√ß√µes vetoriais: {str(ve)}")
                else:
                    st.error("‚ùå Extens√£o pgvector N√ÉO est√° instalada!")
                    st.info("A extens√£o 'pgvector' √© necess√°ria para opera√ß√µes de pesquisa vetorial.")
                    st.code("CREATE EXTENSION vector;", language="sql")
                
                cursor.close()
                conn.close()
                
            except Exception as e:
                st.error(f"‚ùå Erro ao conectar ao banco de dados: {str(e)}")
                
    with vector_tab:
        st.subheader("Tabelas Vetoriais")
        
        with st.spinner("Verificando tabelas vetoriais..."):
            try:
                # Initialize RAG tool if not already done
                if 'multi_rag_tool' not in st.session_state:
                    from multi_table_rag import MultiTableRAGTool
                    try:
                        st.session_state.multi_rag_tool = MultiTableRAGTool()
                    except Exception as init_error:
                        st.error(f"‚ùå Erro ao inicializar MultiTableRAGTool: {init_error}")
                
                # Display tables information
                if hasattr(st.session_state, 'multi_rag_tool'):
                    tables = st.session_state.multi_rag_tool.table_configs
                    
                    if not tables:
                        st.warning("‚ö†Ô∏è Nenhuma tabela vetorial encontrada no banco de dados.")
                        st.info("Fa√ßa upload de documentos na se√ß√£o 'Upload e Vetoriza√ß√£o de Arquivos'.")
                    else:
                        st.success(f"‚úÖ Encontradas {len(tables)} tabelas vetoriais")
                        
                        for table in tables:
                            with st.expander(f"Tabela: {table['name']}"):
                                st.write(f"**Descri√ß√£o**: {table['description']}")
                                st.write(f"**Documentos**: {table.get('doc_count', '?')}")
                                st.write(f"**Chunks**: {table.get('chunk_count', '?')}")
                                st.write(f"**Dimens√£o dos vetores**: {table.get('embed_dim', 1536)}")
                                st.write(f"**Pesquisa h√≠brida**: {'Habilitada' if table.get('hybrid_search', False) else 'Desabilitada'}")
                                
                                if table.get('files'):
                                    st.write("**Arquivos:**")
                                    for file in table['files']:
                                        st.write(f"- {file}")
                
                # Option to run a test query
                if st.button("Executar consulta de teste"):
                    test_query = "O que √© RAG e como funciona?"
                    
                    with st.spinner(f"Executando consulta de teste: '{test_query}'"):
                        try:
                            response = st.session_state.multi_rag_tool.query(test_query)
                            st.json(response)
                        except Exception as qe:
                            st.error(f"‚ùå Erro ao executar consulta de teste: {str(qe)}")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao verificar tabelas vetoriais: {str(e)}")
